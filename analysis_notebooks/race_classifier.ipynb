{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todos\n",
    "----\n",
    "- dummy encode race and attraction and rerun classifiers\n",
    "- binarize labels in general: cm,af.. ->1,2,3,4 \n",
    "\n",
    "- try RF for this cell\n",
    "\n",
    "```\n",
    "X = np.c_[encodings[:-num_of_friends], df['rating'][:-num_of_friends]]\n",
    "\n",
    "rf = LogisticRegression(class_weight='balanced').fit(X, colors_dic[:-num_of_friends])\n",
    "get_multi_label_roc_score(pd.Series(colors_dic[:-num_of_friends]), encodings[:-num_of_friends] ,rf)\n",
    "```\n",
    "\n",
    "- why didn't the LR pick-up the labels in the feature matrix?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajay/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from image_helpers import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!subl image_helpers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2739 2739 2739 2739\n",
      "4359 4359 4359 4359\n",
      "5100 5100 5100 5100\n",
      "5116 5116 5116 5116\n",
      "5124 5124 5124 5124\n"
     ]
    }
   ],
   "source": [
    "_, paths, encodings, arrays_rescaled, X = load_encodings('../data/CM_ALL_faces_encodings.pickle')\n",
    "cm_end_idx = len(paths)\n",
    "paths, encodings, arrays_rescaled, X = append_new_dataset(paths, encodings, arrays_rescaled, X, '../data/AM_ALL_faces_encodings.pickle')\n",
    "am_end_idx = len(paths)\n",
    "paths, encodings, arrays_rescaled, X = append_new_dataset(paths, encodings, arrays_rescaled, X, '../data/AF_ALL_faces_encodings.pickle')\n",
    "af_end_idx = len(paths)\n",
    "paths, encodings, arrays_rescaled, X = append_new_dataset(paths, encodings, arrays_rescaled, X, '../data/CF_ALL_faces_encodings.pickle')\n",
    "cf_end_idx = len(paths)\n",
    "\n",
    "paths, encodings, arrays_rescaled, X = append_new_dataset(paths, encodings, arrays_rescaled, X, '../data/friends_and_myself_pics_faces_encodings.pickle')\n",
    "female_friends_end_idx = len(paths)\n",
    "paths, encodings, arrays_rescaled, X = append_new_dataset(paths, encodings, arrays_rescaled, X, '../data/friends_pics_male_faces_encodings.pickle')\n",
    "male_friends_end_idx = len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 3    2415\n",
       " 4    1056\n",
       " 2     738\n",
       " 5     731\n",
       " 1     160\n",
       "-1      24\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame().from_csv(\n",
    "        '../data/filename_to_rating_lookup_ALL.csv', \n",
    "        index_col=[0]\n",
    "    ) \n",
    "    \n",
    "look_up_file_to_attractiveness_rating = dict(zip(df['Filename'], df['Rating']))\n",
    "paths = [file_path.replace('_face', '').split('/')[-1] for file_path in paths]\n",
    "colors_dic = [look_up_file_to_attractiveness_rating.get(just_file_name) for just_file_name in paths]\n",
    "pd.Series(colors_dic).value_counts()\n",
    "\n",
    "\n",
    "attractiveness_colors_lis=[]\n",
    "for color_number in colors_dic:\n",
    "    if not color_number:\n",
    "        #friends are blue\n",
    "        attractiveness_colors_lis.append(-1)\n",
    "    else:\n",
    "        attractiveness_colors_lis.append(color_number)\n",
    "\n",
    "pd.Series(attractiveness_colors_lis).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "am    1995\n",
       "af    1620\n",
       "cm     744\n",
       "cf     741\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_friends = 24\n",
    "\n",
    "labels = ['cm' for _ in range(cm_end_idx)] + \\\n",
    "['am' for _ in range(am_end_idx - cm_end_idx)] + \\\n",
    "['af' for _ in range(af_end_idx - am_end_idx )] + \\\n",
    "['cf' for _ in range(cf_end_idx - af_end_idx)]\n",
    "\n",
    "\n",
    "pd.Series(labels).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Very strong clf for race\n",
    "\n",
    "*note, balanced didn't make much of a difference in performance of the model but it made a slight amount with the probabilities weights which is why I included it as it invovles less noise with the qualitative analysis and someone's likely to poke holes in the rigor of the analysis so why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9975900651259053"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = LogisticRegression(class_weight='balanced').fit(encodings[:-num_of_friends], labels)\n",
    "get_multi_label_roc_score(pd.Series(labels), encodings[:-num_of_friends] ,rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rf.predict_proba(encodings)).applymap(lambda x: '%.3f' % x)\n",
    "df.columns = ['cm','am', 'af', 'cf']\n",
    "\n",
    "df.index = map(lambda x: x.split('/')[-1].replace('_face.jpg',''), paths)\n",
    "df = df.astype(float)\n",
    "df['rating'] = colors_dic\n",
    "df['labels'] = labels + [np.nan for _ in range(df.__len__() - len(labels))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asian females rated the most attractive overall\n",
    "\n",
    "CFs close 2nd and AZN men last which makes me the question the rater's demographic more. Are they all CF men?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2594086021505375 744\n",
      "3.406207827260459 741\n",
      "3.0791979949874686 1995\n",
      "3.4987654320987653 1620\n"
     ]
    }
   ],
   "source": [
    "print (df[df['labels'] == 'cm']['rating'].mean(), df[df['labels'] == 'cm']['rating'].__len__())\n",
    "print (df[df['labels'] == 'cf']['rating'].mean(), df[df['labels'] == 'cf']['rating'].__len__())\n",
    "print (df[df['labels'] == 'am']['rating'].mean(), df[df['labels'] == 'am']['rating'].__len__())\n",
    "print (df[df['labels'] == 'af']['rating'].mean(), df[df['labels'] == 'af']['rating'].__len__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moderate but reliable to attraction score prediction\n",
    "\n",
    "Now it's fair to say there's a pattern! This shows in our Umaps as a continuum across the cluster from most attractive on one of hte cluster to least attractive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7665963430592047"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = LogisticRegression(class_weight='balanced').fit(encodings[:-num_of_friends], colors_dic[:-num_of_friends])\n",
    "get_multi_label_roc_score(pd.Series(colors_dic[:-num_of_friends]), encodings[:-num_of_friends] ,rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "### Adding attraction vector to the images, no difference in performance\n",
    "\n",
    "So I accidently included the label in the feature matrix as a column and it made NO difference in the performance... this makes me question the classifier (LR) in it's ability... strange.\n",
    "\n",
    "which means there's unlikely to be a racial bias within the ratings.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'cf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-da29fc1d9015>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencodings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnum_of_friends\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnum_of_friends\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnum_of_friends\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mget_multi_label_roc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolors_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnum_of_friends\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencodings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnum_of_friends\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0;32m-> 1223\u001b[0;31m                          order=\"C\")\n\u001b[0m\u001b[1;32m   1224\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    431\u001b[0m                                       force_all_finite)\n\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'cf'"
     ]
    }
   ],
   "source": [
    "X = np.c_[encodings[:-num_of_friends], df['labels'][:-num_of_friends]]\n",
    "\n",
    "rf = LogisticRegression(class_weight='balanced').fit(X, colors_dic[:-num_of_friends])\n",
    "get_multi_label_roc_score(pd.Series(colors_dic[:-num_of_friends]), encodings[:-num_of_friends] ,rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "743 743 743 743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "638"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, paths, encodings, arrays_rescaled, X = load_encodings('../data/tinder_pics_dislikes_faces_firsts_deduped_encodings.pickle')\n",
    "\n",
    "paths, encodings, arrays_rescaled, X = append_new_dataset(paths, encodings, arrays_rescaled, X, '../data/tinder_pics_likes_faces_deduped_firsts_encodings.pickle')\n",
    "# paths, encodings, arrays_rescaled, X = append_new_dataset(paths, encodings, arrays_rescaled, X, '../data/tinder_pics_2017_deduped_firsts_faces_encodings.pickle')\n",
    "\n",
    "num_of_dislikes = len(_)\n",
    "num_of_dislikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(743,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tinder_labels = np.r_[np.zeros(num_of_dislikes), np.ones(len(paths) - num_of_dislikes )]\n",
    "tinder_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7559084411323586,\n",
       " 0.7574404761904762,\n",
       " 0.04489589750987322,\n",
       " array([0.68229167, 0.74888393, 0.75744048, 0.82264717, 0.76827897]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = LogisticRegression(class_weight='balanced').fit(encodings, tinder_labels)\n",
    "# (clf, feature_M, labels, class_imbalance=True)\n",
    "score_classifier(rf, encodings, tinder_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994 994 994 994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(994,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths, encodings, arrays_rescaled, X = append_new_dataset(paths, encodings, arrays_rescaled, X, '../data/tinder_pics_2017_deduped_firsts_faces_encodings.pickle')\n",
    "tinder_labels = np.r_[np.zeros(num_of_dislikes), np.ones(len(paths) - num_of_dislikes )]\n",
    "tinder_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better with more images\n",
    "\n",
    "with 2017 appended nearly 0.7914646779270329, so there's definitely a pattern, if I wanted to train it. further I could just add all pictures instead of just the firsts. \n",
    "\n",
    "How to figure out what explicitly is this pattern? This is also needed above for the attraction scores\n",
    "\n",
    "methods to augment images:\n",
    "------------\n",
    "- blurr, \n",
    "- jitter, \n",
    "- random block, \n",
    "- picture mirror even orientation, \n",
    "- include all instead of first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.79185908628994,\n",
       " 0.7889539930555555,\n",
       " 0.026717800671208273,\n",
       " array([0.78895399, 0.80501761, 0.78697183, 0.7482533 , 0.8300987 ]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = LogisticRegression(class_weight='balanced').fit(encodings, tinder_labels)\n",
    "\n",
    "score_classifier(rf, encodings, tinder_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
